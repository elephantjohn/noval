#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç™¾åº¦AIæ–‡æœ¬å®¡æ ¸æ‰¹é‡æ£€æµ‹å·¥å…·
å¯¹æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡æœ¬æ–‡ä»¶è¿›è¡Œå†…å®¹å®¡æ ¸
"""

import os
import sys
import time
import json
import requests
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import re

# å¯é€‰ï¼šç”¨äºè‡ªåŠ¨ä¿®å¤ä¸åˆè§„å†…å®¹çš„å¯¹è¯å¤§æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆå¤ç”¨é¡¹ç›®é‡Œçš„ERNIEå®¢æˆ·ç«¯ï¼‰
try:
    from novel_runner.client import BaiduErnieClient  # type: ignore
except Exception:  # noqa: BLE001
    BaiduErnieClient = None  # type: ignore


class BaiduTextCensor:
    """ç™¾åº¦æ–‡æœ¬å®¡æ ¸å®¢æˆ·ç«¯"""
    
    TOKEN_URL = "https://aip.baidubce.com/oauth/2.0/token"
    CENSOR_URL = "https://aip.baidubce.com/rest/2.0/solution/v1/text_censor/v2/user_defined"
    
    def __init__(self, api_key: str, secret_key: str):
        self.api_key = api_key
        self.secret_key = secret_key
        self._access_token: Optional[str] = None
        self._token_expiry: float = 0.0
    
    def _get_access_token(self) -> str:
        """è·å–è®¿é—®ä»¤ç‰Œ"""
        # å¦‚æœtokenæœªè¿‡æœŸåˆ™ç›´æ¥è¿”å›
        if self._access_token and time.time() < (self._token_expiry - 60):
            return self._access_token
        
        print("[TOKEN] æ­£åœ¨è·å–è®¿é—®ä»¤ç‰Œ...")
        
        params = {
            "grant_type": "client_credentials",
            "client_id": self.api_key,
            "client_secret": self.secret_key,
        }
        
        try:
            response = requests.post(self.TOKEN_URL, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            
            if "access_token" not in data:
                raise Exception(f"è·å–tokenå¤±è´¥: {data}")
            
            self._access_token = data["access_token"]
            expires_in = data.get("expires_in", 2592000)  # é»˜è®¤30å¤©
            self._token_expiry = time.time() + expires_in
            
            print(f"[TOKEN] è®¿é—®ä»¤ç‰Œè·å–æˆåŠŸï¼Œæœ‰æ•ˆæœŸ: {expires_in}ç§’")
            return self._access_token
            
        except Exception as e:
            raise Exception(f"è·å–è®¿é—®ä»¤ç‰Œå¤±è´¥: {e}")
    
    def censor_text(self, text: str) -> Dict:
        """å®¡æ ¸æ–‡æœ¬å†…å®¹"""
        access_token = self._get_access_token()
        
        params = {"access_token": access_token}
        data = {"text": text}
        
        try:
            response = requests.post(
                self.CENSOR_URL, 
                params=params, 
                data=data, 
                timeout=30
            )
            response.raise_for_status()
            return response.json()
            
        except Exception as e:
            raise Exception(f"æ–‡æœ¬å®¡æ ¸è¯·æ±‚å¤±è´¥: {e}")


def load_env_file(env_path: Path) -> Dict[str, str]:
    """åŠ è½½.envæ–‡ä»¶"""
    env_vars = {}
    if env_path.exists():
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    env_vars[key.strip()] = value.strip().strip('"').strip("'")
    return env_vars


def read_text_file(file_path: Path) -> str:
    """è¯»å–æ–‡æœ¬æ–‡ä»¶å†…å®¹"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")


def analyze_censor_result(result: Dict) -> Tuple[bool, str]:
    """åˆ†æå®¡æ ¸ç»“æœ"""
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if "error_code" in result:
            return False, f"APIé”™è¯¯ {result['error_code']}: {result.get('error_msg', 'æœªçŸ¥é”™è¯¯')}"
        
        # è·å–å®¡æ ¸ç»“è®º
        conclusion_type = result.get("conclusionType", 1)
        conclusion = result.get("conclusion", "æœªçŸ¥")
        
        # conclusionType: 1-åˆè§„ï¼Œ2-ä¸åˆè§„ï¼Œ3-ç–‘ä¼¼ï¼Œ4-å®¡æ ¸å¤±è´¥
        is_compliant = conclusion_type == 1
        
        if not is_compliant:
            violation_info = []
            
            # åˆ†æå…·ä½“è¿è§„ä¿¡æ¯
            data = result.get("data", [])
            for item in data:
                if item.get("type") and item.get("msg"):
                    violation_info.append(f"ç±»å‹:{item['type']} - {item['msg']}")

                    # è¯¦ç»†çš„å‘½ä¸­ä¿¡æ¯
                    hits = item.get("hits", [])
                    for hit in hits:
                        words = hit.get("words")
                        if isinstance(words, list):
                            joined = "ã€".join(str(w) for w in words)
                            violation_info.append(f"  å‘½ä¸­è¯æ±‡: {joined}")
                        elif isinstance(words, str):
                            violation_info.append(f"  å‘½ä¸­è¯æ±‡: {words}")
            
            detail = f"ç»“è®º: {conclusion}"
            if violation_info:
                detail += f"\nè¯¦ç»†ä¿¡æ¯:\n" + "\n".join(violation_info)
            
            return False, detail
        
        return True, f"å†…å®¹åˆè§„ - {conclusion}"
        
    except Exception as e:
        return False, f"ç»“æœè§£æå¤±è´¥: {e}"


def extract_hit_words(detail: str) -> List[str]:
    """ä»è§£æåçš„è¯¦æƒ…æ–‡æœ¬ä¸­æå–å‘½ä¸­è¯æ±‡åˆ—è¡¨ã€‚"""
    hits: List[str] = []
    for line in detail.split("\n"):
        s = line.strip()
        if s.startswith("å‘½ä¸­è¯æ±‡") or s.startswith("å‘½ä¸­è¯"):
            parts = re.split(r"[:ï¼š]", s, maxsplit=1)
            if len(parts) == 2:
                words = re.split(r"[ã€ï¼Œ,\s]+", parts[1].strip())
                hits.extend([w for w in words if w])
    # å»é‡ä¿æŒé¡ºåº
    seen = set()
    ordered: List[str] = []
    for w in hits:
        if w not in seen:
            seen.add(w)
            ordered.append(w)
    return ordered


def batch_censor_directory(
    directory: Path, 
    censor_client: BaiduTextCensor,
    file_extensions: List[str] = ['.md', '.txt'],
    auto_repair: bool = False,
    repair_client: Optional["BaiduErnieClient"] = None,
    repair_model: str = "ernie-4.5-turbo-128k",
    inplace: bool = False,
    max_rounds: int = 10,
) -> Dict[str, Dict]:
    """æ‰¹é‡å®¡æ ¸ç›®å½•ä¸‹çš„æ–‡ä»¶"""
    
    if not directory.exists() or not directory.is_dir():
        raise Exception(f"ç›®å½•ä¸å­˜åœ¨æˆ–ä¸æ˜¯æœ‰æ•ˆç›®å½•: {directory}")
    
    # è·å–æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶
    files_to_check = []
    for ext in file_extensions:
        files_to_check.extend(directory.glob(f"*{ext}"))
    
    if not files_to_check:
        print(f"[INFO] ç›®å½• {directory} ä¸‹æ²¡æœ‰æ‰¾åˆ° {file_extensions} æ ¼å¼çš„æ–‡ä»¶")
        return {}
    
    print(f"[INFO] æ‰¾åˆ° {len(files_to_check)} ä¸ªæ–‡ä»¶å¾…å®¡æ ¸")
    print(f"[INFO] æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {', '.join(file_extensions)}")
    print("-" * 60)
    
    results = {}
    
    for i, file_path in enumerate(files_to_check, 1):
        print(f"[{i}/{len(files_to_check)}] æ­£åœ¨å®¡æ ¸: {file_path.name}")
        
        try:
            # è¯»å–æ–‡ä»¶å†…å®¹
            content = read_text_file(file_path)
            
            if not content.strip():
                print(f"  âš ï¸  æ–‡ä»¶ä¸ºç©ºï¼Œè·³è¿‡å®¡æ ¸")
                results[str(file_path)] = {
                    "status": "skipped",
                    "reason": "æ–‡ä»¶å†…å®¹ä¸ºç©º"
                }
                continue
            
            print(f"  ğŸ“„ æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
            
            # å¦‚æœå†…å®¹è¿‡é•¿ï¼Œå¯èƒ½éœ€è¦åˆ†æ®µå®¡æ ¸ï¼ˆç™¾åº¦APIæœ‰é•¿åº¦é™åˆ¶ï¼‰
            if len(content) > 10000:
                print(f"  âš ï¸  æ–‡ä»¶å†…å®¹è¾ƒé•¿({len(content)}å­—ç¬¦)ï¼Œå»ºè®®åˆ†æ®µå®¡æ ¸")
            
            # å®¡æ ¸-ä¿®å¤-å¤å®¡å¾ªç¯
            round_idx = 0
            fixed_path_str = ""
            current_text = content
            current_detail = ""
            current_raw = None
            while True:
                print(f"  ğŸ” æ­£åœ¨è°ƒç”¨å®¡æ ¸æ¥å£...")
                censor_result = censor_client.censor_text(current_text)
                current_raw = censor_result
                is_compliant, detail = analyze_censor_result(censor_result)
                current_detail = detail
                if is_compliant:
                    print(f"  âœ… {detail}")
                    # é€šè¿‡åˆ™æ ¹æ®inplaceå†³å®šæ˜¯å¦å†™å…¥ï¼ˆè‹¥ä¹‹å‰æœ‰ä¿®å¤è¿‡éœ€è¦è½ç›˜ï¼‰
                    if round_idx > 0:
                        if inplace:
                            file_path.write_text(current_text, encoding="utf-8")
                            fixed_path_str = str(file_path)
                        else:
                            fixed_file = file_path.with_name(file_path.stem + "_ä¿®å¤" + file_path.suffix)
                            fixed_file.write_text(current_text, encoding="utf-8")
                            fixed_path_str = str(fixed_file)
                    results[str(file_path)] = {
                        "status": "compliant",
                        "detail": detail,
                        "raw_result": current_raw,
                        "fixed_file": fixed_path_str,
                    }
                    break
                # ä¸åˆè§„
                print(f"  âŒ å®¡æ ¸ä¸é€šè¿‡:")
                for line in detail.split('\n'):
                    print(f"     {line}")
                if not auto_repair or repair_client is None or round_idx >= max_rounds:
                    # æ— æ³•æˆ–ä¸å†ä¿®å¤ï¼Œç›´æ¥è¿”å›ä¸åˆè§„
                    results[str(file_path)] = {
                        "status": "non_compliant",
                        "detail": detail,
                        "raw_result": current_raw,
                        "fixed_file": fixed_path_str,
                    }
                    break
                # æ‰§è¡Œä¿®å¤
                print(f"  ğŸ›   è§¦å‘è‡ªåŠ¨ä¿®å¤: ç¬¬{round_idx+1}è½® â€¦")
                try:
                    hits = extract_hit_words(detail)
                    fixed_text = auto_repair_text(
                        repair_client=repair_client,
                        model=repair_model,
                        original_text=current_text,
                        violation_hint=detail,
                        hit_words=hits,
                    )
                    current_text = fixed_text
                    round_idx += 1
                    # ä¸­é—´è½®æ¬¡å…ˆè½ç›˜ä¸ºä¸´æ—¶æ–‡ä»¶ï¼Œä¾¿äºæ’æŸ¥
                    temp_file = file_path.with_name(f"{file_path.stem}_ä¿®å¤_round{round_idx}{file_path.suffix}")
                    temp_file.write_text(current_text, encoding="utf-8")
                    fixed_path_str = str(temp_file)
                    print(f"  âœ… ä¿®å¤äº§ç”Ÿ â†’ {fixed_path_str}ï¼Œå°†å¤å®¡â€¦")
                except Exception as e:
                    print(f"  âŒ ä¿®å¤å¤±è´¥: {e}")
                    results[str(file_path)] = {
                        "status": "error",
                        "detail": f"ä¿®å¤å¤±è´¥: {e}",
                    }
                    break
            
        except Exception as e:
            error_msg = f"å¤„ç†å¤±è´¥: {e}"
            print(f"  âŒ {error_msg}")
            results[str(file_path)] = {
                "status": "error",
                "detail": error_msg
            }
        
        # è¯·æ±‚é—´éš”ï¼Œé¿å…é¢‘ç‡é™åˆ¶
        if i < len(files_to_check):
            print(f"  â±ï¸  ç­‰å¾…2ç§’åç»§ç»­...")
            time.sleep(2)
        
        print()
    
    return results


def print_summary(results: Dict[str, Dict]):
    """æ‰“å°å®¡æ ¸ç»“æœæ±‡æ€»"""
    print("=" * 60)
    print("ğŸ“Š å®¡æ ¸ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    total = len(results)
    compliant = sum(1 for r in results.values() if r["status"] == "compliant")
    non_compliant = sum(1 for r in results.values() if r["status"] == "non_compliant")
    errors = sum(1 for r in results.values() if r["status"] == "error")
    skipped = sum(1 for r in results.values() if r["status"] == "skipped")
    
    print(f"æ€»æ–‡ä»¶æ•°: {total}")
    print(f"âœ… åˆè§„: {compliant}")
    print(f"âŒ ä¸åˆè§„: {non_compliant}")
    print(f"âš ï¸  é”™è¯¯: {errors}")
    print(f"â­ï¸  è·³è¿‡: {skipped}")
    
    if non_compliant > 0:
        print("\nğŸš¨ ä¸åˆè§„æ–‡ä»¶è¯¦æƒ…:")
        print("-" * 40)
        for file_path, result in results.items():
            if result["status"] == "non_compliant":
                print(f"ğŸ“ {Path(file_path).name}")
                print(f"   {result['detail']}")
                if result.get("fixed_file"):
                    print(f"   ğŸ›   ä¿®å¤æ–‡ä»¶: {result['fixed_file']}")
                print()


def censor_single_file(
    file_path: Path,
    censor_client: BaiduTextCensor,
    auto_repair: bool = False,
    repair_client: Optional["BaiduErnieClient"] = None,
    repair_model: str = "ernie-4.5-turbo-128k",
    inplace: bool = False,
    max_rounds: int = 10,
) -> Dict[str, Dict]:
    """å®¡æ ¸å•ä¸ªæ–‡ä»¶ï¼ˆæ”¯æŒå¯é€‰è‡ªåŠ¨ä¿®å¤ï¼‰ã€‚"""
    if not file_path.exists() or not file_path.is_file():
        raise Exception(f"æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸å¯è¯»: {file_path}")

    print(f"[FILE] å®¡æ ¸æ–‡ä»¶: {file_path.name}")
    content = read_text_file(file_path)
    if not content.strip():
        print("  âš ï¸  æ–‡ä»¶ä¸ºç©ºï¼Œè·³è¿‡å®¡æ ¸")
        return {str(file_path): {"status": "skipped", "reason": "æ–‡ä»¶å†…å®¹ä¸ºç©º"}}

    print(f"  ğŸ“„ æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
    if len(content) > 10000:
        print(f"  âš ï¸  æ–‡ä»¶å†…å®¹è¾ƒé•¿({len(content)}å­—ç¬¦)ï¼Œå»ºè®®åˆ†æ®µå®¡æ ¸")

    # å®¡æ ¸-ä¿®å¤-å¤å®¡å¾ªç¯
    current_text = content
    fixed_path_str = ""
    for round_idx in range(max_rounds + 1):
        print("  ğŸ” æ­£åœ¨è°ƒç”¨å®¡æ ¸æ¥å£â€¦")
        censor_result = censor_client.censor_text(current_text)
        is_compliant, detail = analyze_censor_result(censor_result)
        if is_compliant:
            print(f"  âœ… {detail}")
            if round_idx > 0:
                if inplace:
                    file_path.write_text(current_text, encoding="utf-8")
                    fixed_path_str = str(file_path)
                else:
                    fixed_file = file_path.with_name(file_path.stem + "_ä¿®å¤" + file_path.suffix)
                    fixed_file.write_text(current_text, encoding="utf-8")
                    fixed_path_str = str(fixed_file)
            return {str(file_path): {
                "status": "compliant",
                "detail": detail,
                "raw_result": censor_result,
                "fixed_file": fixed_path_str,
            }}

        print("  âŒ å®¡æ ¸ä¸é€šè¿‡:")
        for line in detail.split("\n"):
            print(f"     {line}")
        if not auto_repair or repair_client is None or round_idx >= max_rounds:
            return {str(file_path): {
                "status": "non_compliant",
                "detail": detail,
                "raw_result": censor_result,
                "fixed_file": fixed_path_str,
            }}
        print(f"  ğŸ›   è§¦å‘è‡ªåŠ¨ä¿®å¤: ç¬¬{round_idx+1}è½® â€¦")
        hits = extract_hit_words(detail)
        fixed_text = auto_repair_text(
            repair_client=repair_client,
            model=repair_model,
            original_text=current_text,
            violation_hint=detail,
            hit_words=hits,
        )
        current_text = fixed_text
        temp_file = file_path.with_name(f"{file_path.stem}_ä¿®å¤_round{round_idx+1}{file_path.suffix}")
        temp_file.write_text(current_text, encoding="utf-8")
        fixed_path_str = str(temp_file)
        print(f"  âœ… ä¿®å¤äº§ç”Ÿ â†’ {fixed_path_str}ï¼Œå°†å¤å®¡â€¦")


def auto_repair_text(
    repair_client: "BaiduErnieClient",
    model: str,
    original_text: str,
    violation_hint: str,
    hit_words: Optional[List[str]] = None,
) -> str:
    """ä½¿ç”¨å¤§æ¨¡å‹è‡ªåŠ¨é‡å†™æ–‡æœ¬ä¸ºåˆè§„ç‰ˆæœ¬ã€‚"""
    system_prompt = (
        "ä½ æ˜¯æ–‡æœ¬åˆè§„ç¼–è¾‘ã€‚\n"
        "åªå…è®¸å¯¹å‘½ä¸­è¿è§„è¯æ‰€åœ¨çš„å¥å­åšæœ€å°å¹…åº¦æ”¹å†™æˆ–åŒä¹‰æ›¿æ¢, å…¶ä»–å¥å­ä¸€å­—ä¸åŠ¨ã€‚\n"
        "ä¿æŒåŸæœ‰ä¿¡æ¯é‡ä¸æ—¶é—´é¡ºåºä¸å› æœå…³ç³»ä¸å˜, ä¸æ–°å¢äººç‰©ä¸äº‹ä»¶, ä¸æ‰©å†™ã€‚\n"
        "è¿”å›å®Œæ•´æ­£æ–‡, å…¶ä½™ä½ç½®ä¿æŒä¸åŸæ–‡å®Œå…¨ä¸€è‡´, ä¸åŠ è§£é‡Šã€‚"
    )
    hit_text = "ã€".join(hit_words) if hit_words else ""
    user_prompt = (
        "ã€å‘½ä¸­è¯æ±‡ã€‘\n" + hit_text +
        "\n\nã€ä¸åˆè§„æç¤ºã€‘\n" + violation_hint +
        "\n\nã€ä¿®è®¢è¦æ±‚ã€‘\nè¯·å°†ä¸Šè¿°å‘½ä¸­è¯åœ¨åŸæ–‡ä¸­æ›¿æ¢ä¸ºä¸è¿è§„ä½†è¯­ä¹‰ç›¸è¿‘çš„è¡¨è¾¾, æˆ–å¯¹åŒ…å«å®ƒä»¬çš„æ•´å¥è¿›è¡Œæ”¹å†™ä»¥ç§»é™¤è¯¥è¯ã€‚\nåªæ”¹è¿™äº›å¥å­, å…¶ä»–éƒ¨åˆ†ä¿æŒå®Œå…¨ä¸å˜ã€‚\n"+
        "\nã€å¾…ä¿®è®¢æ­£æ–‡ã€‘\n" + original_text
    )
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]
    data = repair_client.chat_completions(
        model=model,
        messages=messages,
        temperature=0.4,
        top_p=0.85,
        max_tokens=6000,
    )
    # å…¼å®¹å¤šç§è¿”å›ç»“æ„
    if isinstance(data, dict):
        if "result" in data and isinstance(data["result"], str):
            return data["result"]
        if "choices" in data:
            choice = data["choices"][0]
            msg = choice.get("message") or {}
            if isinstance(msg, dict) and isinstance(msg.get("content"), str):
                return msg["content"]
    return str(data)


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python text_censor_batch.py <è·¯å¾„> [--auto-repair] [--inplace] [--repair-model=ernie-4.5-turbo-128k] [--max-rounds=10]")
        print("è¯´æ˜: <è·¯å¾„> å¯ä¸ºç›®å½•æˆ–å•ä¸ªæ–‡ä»¶")
        print("ç¤ºä¾‹: python text_censor_batch.py ./chapters --auto-repair --repair-model=ernie-4.5-turbo-128k --max-rounds=10")
        sys.exit(1)

    # ç®€æ˜“å‚æ•°è§£æ
    target_path = Path(sys.argv[1])
    auto_repair = any(arg == "--auto-repair" for arg in sys.argv[2:])
    inplace = any(arg == "--inplace" for arg in sys.argv[2:])
    repair_model = "ernie-4.5-turbo-128k"
    max_rounds = 10
    for arg in sys.argv[2:]:
        if arg.startswith("--repair-model="):
            repair_model = arg.split("=", 1)[1] or repair_model
        if arg.startswith("--max-rounds="):
            try:
                max_rounds = int(arg.split("=", 1)[1])
            except Exception:
                pass
    
    print("ğŸ” ç™¾åº¦AIæ–‡æœ¬å®¡æ ¸æ‰¹é‡æ£€æµ‹å·¥å…·")
    print("=" * 60)
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    env_file = Path('.env')
    env_vars = load_env_file(env_file)
    
    api_key = env_vars.get('TEXT_API_KEY') or os.getenv('TEXT_API_KEY')
    secret_key = env_vars.get('TEXT_SECRET_KEY') or os.getenv('TEXT_SECRET_KEY')
    baidu_api_key = env_vars.get('BAIDU_API_KEY') or os.getenv('BAIDU_API_KEY')
    
    if not api_key or not secret_key:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° TEXT_API_KEY æˆ– TEXT_SECRET_KEY")
        print("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®:")
        print("TEXT_API_KEY=your_api_key_here")
        print("TEXT_SECRET_KEY=your_secret_key_here")
        sys.exit(1)
    
    label = "ç›®æ ‡ç›®å½•" if target_path.is_dir() else "ç›®æ ‡æ–‡ä»¶"
    print(f"ğŸ“‚ {label}: {target_path.absolute()}")
    print(f"ğŸ”‘ æ–‡æœ¬å®¡æ ¸AK: {api_key[:8]}...{api_key[-4:]}")
    if auto_repair:
        if BaiduErnieClient is None:
            print("âŒ è‡ªåŠ¨ä¿®å¤ä¸å¯ç”¨: æœªæ‰¾åˆ°å¯¹è¯æ¨¡å‹å®¢æˆ·ç«¯ä¾èµ–ã€‚")
            sys.exit(1)
        if not baidu_api_key:
            print("âŒ è‡ªåŠ¨ä¿®å¤ä¸å¯ç”¨: æœªé…ç½® BAIDU_API_KEYã€‚")
            sys.exit(1)
        print(f"ğŸ›   è‡ªåŠ¨ä¿®å¤å·²å¼€å¯ï¼Œæ¨¡å‹: {repair_model}")
    print()
    
    try:
        # åˆå§‹åŒ–å®¡æ ¸å®¢æˆ·ç«¯
        censor_client = BaiduTextCensor(api_key, secret_key)

        repair_client = None
        if auto_repair and BaiduErnieClient is not None and baidu_api_key:
            # å¤ç”¨é¡¹ç›®ERNIEå®¢æˆ·ç«¯ï¼Œæ”¯æŒç›´æ¥ç”¨ BAIDU_API_KEY
            repair_client = BaiduErnieClient()
        
        # æ‰§è¡Œæ‰¹é‡å®¡æ ¸
        if target_path.is_file():
            results = censor_single_file(
                target_path,
                censor_client,
                auto_repair=auto_repair,
                repair_client=repair_client,
                repair_model=repair_model,
                inplace=inplace,
                max_rounds=max_rounds,
            )
        else:
            results = batch_censor_directory(
                target_path,
                censor_client,
                auto_repair=auto_repair,
                repair_client=repair_client,
                repair_model=repair_model,
                inplace=inplace,
                max_rounds=max_rounds,
            )
        
        # æ‰“å°æ±‡æ€»
        print_summary(results)
        
        # ä¿å­˜è¯¦ç»†ç»“æœåˆ°JSONæ–‡ä»¶
        result_file = Path("censor_results.json")
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {result_file.absolute()}")
        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
